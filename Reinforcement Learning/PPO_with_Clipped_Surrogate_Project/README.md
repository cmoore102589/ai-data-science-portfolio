# PPO with Clipped Surrogate Objective

## Overview
This project explores the PPO algorithm with a focus on the clipped surrogate objective, a technique that stabilizes training by limiting policy updates.

## Features
- Implementation of PPO with clipping
- Comparative analysis with other policy gradient methods
- Performance metrics and visualizations

## Getting Started
1. Clone the repository.
2. Install dependencies: `pip install -r requirements.txt`
3. Run the training script: `python train_clipped_ppo.py`

## Results
The clipped surrogate objective enhances training stability and performance, as evidenced by improved reward metrics.

## Acknowledgments
Based on the PPO algorithm introduced by Schulman et al.
