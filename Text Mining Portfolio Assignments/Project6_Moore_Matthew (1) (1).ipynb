{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891d4f03",
   "metadata": {},
   "source": [
    "# Project 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc2f5e",
   "metadata": {},
   "source": [
    "You are a data scientist working for a Consulting Firm. You are given a dataset containing in sentiment140.csv \n",
    "\n",
    "Download sentiment140.csv. The data set has six columns without header:\n",
    "\n",
    "- the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "- the id of the tweet (2087)\n",
    "- the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "- the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "- the user that tweeted (robotickilldozr)\n",
    "- the text of the tweet (\"Lyx is cool\")\n",
    "\n",
    "Data source: Sentiment140Links to an external site. (Go, A. et. al., Stanford University)\n",
    "\n",
    " \n",
    "Steps and Questions: \n",
    "Our goal is to forecast the polarity of the tweet using the text of the tweet.\n",
    "\n",
    "1. Load the dataset of sentiment140.csv into memory.\n",
    "2. Clean and preprocess the texts.\n",
    "3. Build the first model based on pipeline using the support vector machines.\n",
    "4. Check the first model. Is it a good model based on the selected evaluation metrics? Please justify your answer.\n",
    "5. Create the second model using pipeline, grid search CV for the hyperparameters for the estimators. (Please see all the potential parameters at Scikit Learn TfidfVectorizerLinks to an external site. and Scikit Learn SVCLinks to an external site..)\n",
    "6. Tune the second model using the support vector machines and perform model diagnostics. Is it a good model? Please justify your answer.\n",
    "7. Build the third model using pipeline, grid search CV, hyperparameter for the following classifiers:\n",
    "    - Logistic regression\n",
    "    - Random Forest\n",
    "    - Support Vector Machine\n",
    "\n",
    "8. Tune the third model and perform model diagnostics. Is it a good model? Please justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456850eb",
   "metadata": {},
   "source": [
    "## Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ea02d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmoore/opt/anaconda3/lib/python3.8/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/Users/matthewmoore/opt/anaconda3/lib/python3.8/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matthewmoore/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matthewmoore/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer, TfidfTransformer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a8bb2",
   "metadata": {},
   "source": [
    "## 1. Load the dataset of sentiment140.csv into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0613c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1                             2         3  \\\n",
       "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599995  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                       4                                                  5  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Dataset\n",
    "df = pd.read_csv('/Users/matthewmoore/Downloads/sentiment140.csv', encoding = 'ISO-8859-1', header = None)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca740cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change Column Names\n",
    "df.columns = ['polarity', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f296d72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   polarity  1600000 non-null  int64 \n",
      " 1   id        1600000 non-null  int64 \n",
      " 2   date      1600000 non-null  object\n",
      " 3   query     1600000 non-null  object\n",
      " 4   user      1600000 non-null  object\n",
      " 5   text      1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c90bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity    0.0\n",
       "id          0.0\n",
       "date        0.0\n",
       "query       0.0\n",
       "user        0.0\n",
       "text        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "percent_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f20f7",
   "metadata": {},
   "source": [
    "## 2. Clean and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c066fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Handle missing values\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join words back into a cleaned string\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply the cleaning function to the dataset\n",
    "df['clean_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06de059b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          switchfoot httptwitpiccomyzl awww thats bummer...\n",
       "1          upset cant update facebook texting might cry r...\n",
       "2          kenichan dived many times ball managed save re...\n",
       "3                           whole body feels itchy like fire\n",
       "4                   nationwideclass behaving im mad cant see\n",
       "                                 ...                        \n",
       "1599995                        woke school best feeling ever\n",
       "1599996    thewdbcom cool hear old walt interviews httpbl...\n",
       "1599997                      ready mojo makeover ask details\n",
       "1599998    happy th birthday boo alll time tupac amaru sh...\n",
       "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
       "Name: clean_text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9fe370a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "4    0.5\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55d856",
   "metadata": {},
   "source": [
    "## 3. Build the first model based on pipeline using the support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8716db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Creating our tokenzer function from a given sentence\n",
    "def spacy_tokenizer(sentence):\n",
    "   \n",
    "    # Split the sentence into tokens/words\n",
    "    mytokens = nlp(sentence)\n",
    "    # Removing stop words and obtain the lemma\n",
    "    mytokens = [ word.lemma_ for word in mytokens if word not in stop_words]\n",
    "    return mytokens   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e9a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['polarity']\n",
    "\n",
    "# Split the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a6518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280000,), (320000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b951f7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280000,), (320000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f00d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer, ngram_range = (1,1))\n",
    "\n",
    "# SVM classifier\n",
    "svm_classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403aa4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline for SVM Classifier\n",
    "pipeline_svc = Pipeline([\n",
    "    ('vectorizer', tfidf_vector),\n",
    "    ('classifier', svm_classifier)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_svc.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Metrics\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bef9e",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation for SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55127ce8",
   "metadata": {},
   "source": [
    "[Fill in info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0e487",
   "metadata": {},
   "source": [
    "## 5. Create the second model using pipeline, grid search CV for the hyperparameters for the estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795226af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define TfidfVectorizer and SVC Parameters\n",
    "param_grid = {\n",
    "    'tfidf__max_df': [0.80, 1.0],\n",
    "    'tfidf__min_df': [1, 5],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__kernel': ['linear', 'rbf'],\n",
    "    'svc__gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eef7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline \n",
    "pipeline_svc = Pipeline([\n",
    "    ('vectorizer', tfidf_vector),\n",
    "    ('classifier', svm_classifier)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee08ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460d7c1",
   "metadata": {},
   "source": [
    "## 6. Tune the second model using the support vector machines and perform model diagnostics. Is it a good model? Please justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34562b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter and Model Evaluation\n",
    "print(\"Best Parameters:\\n\", grid_search.best_params_)\n",
    "\n",
    "y_pred_grid = grid_search.predict(X_test)\n",
    "print(\"\\nAccuracy (Tuned Model):\", accuracy_score(y_test, y_pred_grid))\n",
    "print(\"\\nClassification Report (Tuned Model):\\n\", classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e6d67",
   "metadata": {},
   "source": [
    "[Fill in info]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de925a1e",
   "metadata": {},
   "source": [
    "## 7. Build the third model using pipeline, grid search CV, hyperparameter for the following classifiers:\n",
    "- Logistic regression\n",
    "- Random Forest\n",
    "- Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bcca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pipeline\n",
    "pipeline_multi = Pipeline([\n",
    "    ('tfidf', tfidf_vector),\n",
    "    ('clf', svm_classifier) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d94960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Parameters for the 3 Classifiers\n",
    "param_grid_multi = [\n",
    "    {\n",
    "        'clf': [LogisticRegression(max_iter=1000)],\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'tfidf__ngram_range': [(1,1), (1,2)]\n",
    "    },\n",
    "    {\n",
    "        'clf': [RandomForestClassifier()],\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "        'tfidf__max_df': [0.75, 1.0]\n",
    "    },\n",
    "    {\n",
    "        'clf': [SVC()],\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__kernel': ['linear', 'rbf'],\n",
    "        'tfidf__min_df': [1, 5]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV with Pre-defined Multi-parameters\n",
    "grid_search_multi = GridSearchCV(pipeline_multi, param_grid_multi, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a555be",
   "metadata": {},
   "source": [
    "## 8. Tune the third model and perform model diagnostics. Is it a good model? Please justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9aa367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter and Model Evaluation\n",
    "print(\"Best Parameters for Multi-Classifiers:\\n\", grid_search_multi.best_params_)\n",
    "\n",
    "y_pred_multi = grid_search_multi.predict(X_test)\n",
    "print(\"\\nAccuracy (Multi-Classifier Model):\", accuracy_score(y_test, y_pred_multi))\n",
    "print(\"\\nClassification Report (Multi-Classifier Model):\\n\", classification_report(y_test, y_pred_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510c6f1",
   "metadata": {},
   "source": [
    "[Fill in info] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c65744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
